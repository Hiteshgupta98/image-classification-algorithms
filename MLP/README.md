# Forward and Backpropagation algorithm for a Multi Layer Perceptron (MLP)

DataSet used: MNIST dataset

For performing image classification on the multi-class MNIST dataset, implemented the multilayer perceptron algorithm using the sigmoid activation function. We tested several different network architectures before selecting our final architecture for this task. Later we tuned the network to obtain the optimal hyperparamters. 

This network was then used to analyse the accuracy and loss results on the training, validation, and testing datasets.

Results obtained: 
For Training Datatset: Accuracy=90.866
For Validation Dataset: Accuracy=89.49
Achieved an 88.48% testing accuracy using MLP. This in comparison to CNNs is abysmal where we achieve over 99% accuracy. 
